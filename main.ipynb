{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "istanbul_metro = {\n",
    "    \"M2\": [\n",
    "        \"YENIKAPI\", \"VEZNECILER\", \"HALIC\", \"SISHANE\", \"TAKSIM\",\n",
    "        \"OSMANBEY\", \"SISLI\", \"GAYRETTEPE\", \"LEVENT\", \"4 LEVENT\",\n",

    "        \"SANAYI MAH.\", \"ITU\", \"ATATURK OTO SANAYI\", \"DARUSSAFAKA\",\n",
    "        \"HACIOSMAN\"\n",
    "    ],\n",
    "    \"M3\": [\n",
    "        \"BAKIRKOY IDO\", \"OZGURLUK MEYDANI\", \"INCIRLI\", \"HAZNEDAR\", \"ILKYUVA\",\n",
    "        \"MOLLA GURANI\", \"KIRAZLI\", \"YENI MAHALLE\", \"MAHMUTBEY\", \"ISTOC\",\n",
    "        \"IKITELLI SANAYI\", \"TURGUT OZAL\", \"SITELER\", \"BASAK KONUTLARI\", \"METROKENT\",\n",
    "        \"ONURKENT\", \"SEHIR HASTANESI\", \"TOPLU KONUTLAR\", \"KAYASEHIR MERKEZ\"\n",
    "],\n",
    "    \"M4\": [\n",
    "        \"KADIKOY\", \"AYRILIKCESME\", \"ACIBADEM\", \"UNALAN\", \"GOZTEPE\",\n",
    "        \"YENISAHRA\", \"KOZYATAGI\", \"BOSTANCI\", \"KUCUKYALI\", \"MALTEPE\",\n",
    "        \"HUZUREVI\", \"GULSUYU\", \"ESENKENT CEVIZLI\", \"HASTANE\", \"SOGANLIK\",\n",
    "        \"KARTAL\", \"YAKACIK\", \"PENDIK\", \"TAVSANTEPE\", \"FEVZI CAKMAK\",\n",
    "        \"YAYALAR\", \"KURTKOY\", \"SABIHA GOKCEN HAVALIMANI\",\n",
    "    ],\n",
    "    # \"M5\": [\n",
    "    #     \"USKUDAR\", \"FISTIKAGACI\", \"BAGLARBASI\", \"ALTUNIZADE\", \"KISIKLI\",\n",
    "    #     \"BULGURLU\", \"UMRANIYE\", \"CARSI\", \"YAMANEVLER\", \"CAKMAK\",\n",
    "    #     \"IHLAMURKUYU\", \"ALTINSEHIR\", \"IMAM HATIP LISESI\", \"DUDULLU\", \"NECIP FAZIL\",\n",
    "    #     \"CEKMEKOY\", \"MECLIS\", \"SARIGAZI\", \"SANCAKTEPE\", \"SAMANDIRA MERKEZ\"\n",
    "    # ],\n",
    "    \"M6\": [\n",
    "        \"LEVENT  KONKORS\", \"NISPETIYE\", \"ETILER\", \"BOGAZICI\"\n",
    "    ],\n",
    "    \"M7\": [\n",
    "        \"YILDIZ\", \"FULYA\", \"MECIDIYEKOY\", \"CAGLAYAN\", \"KAGITHANE\",\n",
    "        \"NURTEPE\", \"ALIBEYKOY\", \"CIRCIR\", \"VEYSELKARANI\", \"YESILPINAR\",\n",
    "        \"KAZIMKARABEKIR\", \"YENIMAHALLE\", \"KARADENIZ MAH.\", \"TEKSTILKENT\", \"ORUCREIS\",\n",

    "        \"GOZTEPE\", \"MAHMUTBEY\"\n",
    "    ],\n",
    "    # \"M8\": [\n",
    "    #     \"BOSTANCI\", \"EMIN ALI PASA\", \"AYSE KADIN\", \"ICERENKOY\", \"KUCUKBAKKALKOY\", \"KAYISDAGI\",\n",
    "    #     \"MEVLANA\", \"IMES\", \"MODOKO KEYAP\", \"DUDULLU\", \"HUZUR\", \"PARSELLER\"\n",

    "    # ],\n",
    "    \"M9\": [\n",
    "        \"ATAKOY\", \"YENIBOSNA\", \"COBANCESME\", \"29 EKIM CUMHURIYETIHLAS YUVA\", \"SANAYI\", \"MIMAR SINAN\",\n",
    "        \"15 TEMMUZ\", \"HALKALI\", \"ATATURK MAHALLESI\", \"BAHARIYE\", \"MASKO\", \n",
    "        \"IKITELLI SANAYI\", \"ZIYA GOKALP MAH\", \"OLIMPIYAT\"\n",

    "    ],\n",
    "    \"M11\": [\n",
    "        \"GAYRETTEPE\", \"KAGITHANE\", \"HASDAL\", \"KEMERBURGAZ\", \"GOKTURK\", \"IHSANIYE\",\n",
    "        \"ISTANBUL HAVALIMANI\", \"KARGO TERMINALI\", \"TASOLUK\", \"ARNAVUTKOY HASTANE\"\n",

    "    ],\n",
    "    \"M11\": [\n",
    "        \"GAYRETTEPE\", \"KAGITHANE\", \"HASDAL\", \"KEMERBURGAZ\", \"GOKTURK\", \"IHSANIYE\",\n",
    "        \"ISTANBUL HAVALIMANI\", \"KARGO TERMINALI\", \"TASOLUK\", \"ARNAVUTKOY HASTANE\"\n",
    "    ],\n",
    "\n",
    "    \"T5\": [\n",
    "        \"EMINONU\", \"KUCUKPAZAR\", \"CIBALI\", \"FENER\", \"BALAT\",\n",
    "        \"AYVANSARAY\", \"FESHANE\", \"EYUP TELEFERIK\", \"EYUP DEVLET HASTANESI\", \"SILAHTARAGA\",\n",
    "        \"UNIVERSITE\", \"ALIBEYKOY\", \"ALIBEYKOY METRO\", \"CEP OTOGAR\"],\n",
    "\n",
    "    \"T4\": [\n",
    "        \"TOPKAPI\", \"FETIHKAPI\", \"VATAN\", \"EDIRNEKAPI\", \"SEHITLIK\",\n",
    "        \"DEMIRKAPI\", \"TOPCULAR\", \"RAMI\", \"BEREC\", \"SAGMALCILAR\",\n",
    "        \"CUKURCESME\", \"ALI FUAT BASGIL\", \"TASKOPRU\", \"KARADENIZ MAHALLESI\", \"KIPTAS VENEZIA\",\n",
    "        \"CUMHURIYET\", \"BASTABYA\", \"HACI SUKRU\", \"YENIMAHALLE\", \"SULTANCIFTLIGI\",\n",
    "        \"CEBECI\", \"MESCIDI SELAM\"],\n",
    "\n",
    "    \"T1\": [ \n",
    "        \"KABATAS\", \"FINDIKLI\", \"TOPHANE\", \"KARAKOY\", \"EMINONU\",\n",
    "        \"SIRKECI\", \"GULHANE\", \"SULTANAHMET\", \"CEMBERLITAS\", \"BEYAZIT\",\n",
    "        \"LALELI\", \"AKSARAY\", \"YUSUFPASA\", \"HASEKI\", \"FINDIKZADE\",\n",
    "        \"CAPA\", \"PAZARTEKKE\", \"TOPKAPI\", \"ATATURK OGRENCI YURDU\", \"MERKEZEFENDI\",\n",
    "        \"AKSEMSETTIN\", \"MITHATPASA\", \"ZEYTINBURNU\", \"MEHMETAKIF\", \"KERESTECILER\",\n",
    "        \"GUNGOREN\", \"AKINCILAR\", \"SOGANLI\", \"CAMI\", \"GUNESTEPE\",\n",
    "        \"BAGCILAR\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/hourly_transportation_202409.csv')\n",
    "data = data[data[\"line_name\"].isin([\"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"T1\", \"T4\", \"T5\"])]\n",
    "data = data[[\"transition_date\", \"transition_hour\", \"line_name\", \"number_of_passage\", \"station_poi_desc_cd\"]]\n",
    "data = data.rename(columns={\"transition_date\": \"date\", \"transition_hour\": \"hour\", \"line_name\": \"line\", \"number_of_passage\": \"passenger_count\", \"station_poi_desc_cd\": \"station\"})\n",
    "data = data[data[\"hour\"] >= 6]\n",
    "\n",
    "data['station'] = data['station'].str.replace(r'\\(.*?\\)', '', regex=True)\n",
    "# Remove unwanted words (KUZEY, GUNEY, DOGU, BATI) and numbers from the 'station' column\n",
    "data['station'] = data['station'].str.replace(r'\\b(HOL|KUZEY|GUNEY|DOGU|BATI)\\b', '', regex=True)\n",
    "data['station'] = data['station'].str.replace(r'\\b(T4|M3|M7|M9)\\b', '', regex=True)\n",
    "#remove all digits and numbers at the end of the string\n",
    "data['station'] = data['station'].str.replace(r'\\s*\\d+\\s*$', '', regex=True)\n",
    "data['station'] = data['station'].str.replace(r'[\\-/]', '', regex=True)  # Remove symbols: (), -, /\n",
    "data['station'] = data['station'].str.strip()\n",
    "data[\"station\"] = data[\"station\"].astype(str)\n",
    "\n",
    "data = data[~data[\"station\"].str.contains(\"SEYRANTEPE\", na=False)]\n",
    "\n",
    "data = data.groupby(['date', 'hour', 'line', 'station'], as_index=False)['passenger_count'].sum()\n",
    "data = data.groupby(['hour', 'line', 'station'], as_index=False).agg({'passenger_count': 'mean'})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def sort_passenger_data_by_station(data, station_order):\n",
    "    sorted_data = {}\n",

    "\n",
    "    for line, hours in data.items():\n",
    "        if line not in station_order:\n",
    "            print(f\"[UYARI] '{line}' hattı için durak sırası tanımlı değil.\")\n",
    "            continue\n",
    "\n",
    "        line_order = station_order[line]\n",
    "        all_stations_in_data = set()\n",
    "        for hour_data in hours.values():\n",
    "            all_stations_in_data.update(hour_data.keys())\n",
    "\n",
    "        # 1. station_order'da olup dict'te olmayanlar\n",
    "        for station in line_order:\n",
    "            if station not in all_stations_in_data:\n",
    "                print(f\"[Eksik Veri] '{line}' hattında sıralamada olan '{station}' istasyonu veride yok.\")\n",
    "\n",
    "        # 2. dict'te olup station_order'da olmayanlar\n",
    "        for station in all_stations_in_data:\n",
    "            if station not in line_order:\n",
    "                print(f\"[Sıralama Bilgisi Yok] '{line}' hattında veride olan '{station}' istasyonu sıralama listesinde yok.\")\n",
    "\n",

    "        # Asıl sıralama işlemi\n",
    "        sorted_data[line] = {}\n",
    "        for hour, stations in hours.items():\n",
    "            sorted_stations = OrderedDict()\n",
    "            for station in line_order:\n",
    "                if station in stations:\n",
    "                    sorted_stations[station] = stations[station]\n",
    "            sorted_data[line][hour] = sorted_stations\n",
    "\n",
    "    return sorted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for i in range(len(data)):\n",
    "    if data[\"line\"][i] not in dict:\n",
    "        dict[data[\"line\"][i]] = {}\n",
    "    if data[\"hour\"][i] not in dict[data[\"line\"][i]]:\n",
    "        dict[data[\"line\"][i]][data[\"hour\"][i]] = {}\n",
    "    if data[\"station\"][i] not in dict[data[\"line\"][i]][data[\"hour\"][i]]:\n",
    "        dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]] = {}\n",
    "    dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]] = data[\"passenger_count\"][i]\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = sort_passenger_data_by_station(dict, istanbul_metro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = []\n",
    "for line, hours in sorted_data.items():\n",
    "    for hour, stations in hours.items():\n",
    "        for station, count in stations.items():\n",
    "            df_rows.append({\n",
    "                \"line\": line, \"hour\": hour, \"station\": station, \"passenger_count\": count\n",
    "            })\n",
    "\n",
    "data_sorted = pd.DataFrame(df_rows)\n",
    "data_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumulative sum of passenger_count shifted by 1 station\n",
    "data_sorted['cum_passenger_count'] = data_sorted.groupby(['hour', 'line'])['passenger_count'].cumsum()\n",
    "data_sorted['cum_passenger_count'] = data_sorted.groupby(['hour', 'line'])['cum_passenger_count'].shift(fill_value=0)\n",
    "data_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_passenger_count(data, hour, line, station):\n",
    "    data = data[(data[\"hour\"] == hour) & (data[\"line\"] == line)]\n",
    "    station_data = data[data[\"station\"] == station]\n",
    "    passenger_count = station_data[\"passenger_count\"].iloc[0]\n",
    "    total_passenger_count = sum(data[\"passenger_count\"])\n",
    "    cumsum_passenger_count = station_data[\"cum_passenger_count\"].iloc[0]\n",
    "    \n",
    "    direction_2 = passenger_count * cumsum_passenger_count / (total_passenger_count-passenger_count)\n",
    "    direction_1 = passenger_count-direction_2\n",
    "    return direction_1, direction_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted['direction_1'] = None\n",
    "data_sorted['direction_2'] = None\n",
    "\n",
    "\n",
    "for index, row in data_sorted.iterrows():\n",
    "    direction_1, direction_2 = calculate_passenger_count(data_sorted, row['hour'], row['line'], row['station'])\n",
    "    data_sorted.at[index, 'direction_1'] = direction_1\n",
    "    data_sorted.at[index, 'direction_2'] = direction_2\n",
    "data_sorted['direction_1'] = pd.to_numeric(data_sorted['direction_1'], errors='coerce')\n",
    "data_sorted['direction_2'] = pd.to_numeric(data_sorted['direction_2'], errors='coerce')\n",
    "data_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_orig = data_sorted.copy()  # orijinal DataFrame\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for line in df_orig['line'].unique():\n",
    "    df_line = df_orig[df_orig['line'] == line].copy()\n",
    "\n",
    "    for hour, group in df_line.groupby('hour'):\n",
    "        # Sıralı hale getir\n",
    "        group_sorted = group.sort_values(by='station', key=lambda s: s.factorize()[0])\n",
    "\n",
    "        # Orijinal yön (direction_1)\n",
    "        df_orig_dir = group_sorted.copy()\n",
    "        df_orig_dir['in_passenger'] = df_orig_dir['direction_1']\n",
    "        df_orig_dir = df_orig_dir.drop(columns=['direction_2'])\n",
    "\n",
    "        # Ters yön (direction_2)\n",
    "        df_rev_dir = group_sorted.iloc[::-1].copy()\n",
    "        df_rev_dir['line'] = f\"{line}-R\"\n",
    "        df_rev_dir['in_passenger'] = df_rev_dir['direction_2']\n",
    "        df_rev_dir = df_rev_dir.drop(columns=['direction_1'])\n",
    "\n",
    "\n",
    "        new_rows.extend([df_orig_dir, df_rev_dir])\n",
    "         \n",
    "\n",
    "\n",
    "df_split = pd.concat(new_rows, ignore_index=True)\n",
    "df_split = df_split.drop(columns=[\"direction_1\", \"direction_2\", \"cum_passenger_count\", \"passenger_count\"])\n",
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumulative sum of passenger_count shifted by 1 station\n",
    "df_split['cum_passenger_count'] = df_split.groupby(['hour', 'line'])['in_passenger'].cumsum()\n",
    "df_split['cum_passenger_count'] = df_split.groupby(['hour', 'line'])['cum_passenger_count'].shift(fill_value=0)\n",
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_passenger_count(data, hour, line, station):\n",
    "    data = data[(data[\"hour\"] == hour) & (data[\"line\"] == line)]\n",
    "    station_data = data[data[\"station\"] == station]\n",
    "    passenger_count = station_data[\"in_passenger\"].iloc[0]\n",
    "    total_passenger_count = sum(data[\"in_passenger\"])\n",
    "    cumsum_passenger_count = station_data[\"cum_passenger_count\"].iloc[0]\n",
    "    out = passenger_count * cumsum_passenger_count / (total_passenger_count-passenger_count)\n",

    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split['out_passenger'] = None\n",
    "\n",
    "\n",
    "for index, row in df_split.iterrows():\n",
    "    out = calculate_out_passenger_count(df_split, row['hour'], row['line'], row['station'])\n",
    "    df_split.at[index, 'out_passenger'] = out\n",
    "\n",
    "df_split['out_passenger'] = pd.to_numeric(df_split['out_passenger'], errors='coerce')\n",
    "df_split[\"current_passenger\"] = df_split[\"cum_passenger_count\"] - df_split[\"out_passenger\"] + df_split[\"in_passenger\"]\n",
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_split.copy()\n",
    "dict = {}\n",
    "for i in range(len(data)):\n",
    "    if data[\"line\"][i] not in dict:\n",
    "        dict[data[\"line\"][i]] = {}\n",
    "    if data[\"hour\"][i] not in dict[data[\"line\"][i]]:\n",
    "        dict[data[\"line\"][i]][data[\"hour\"][i]] = {}\n",
    "    if data[\"station\"][i] not in dict[data[\"line\"][i]][data[\"hour\"][i]]:\n",
    "        dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]] = {}\n",
    "    dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]][\"in_passenger\"] = float(data[\"in_passenger\"][i])\n",
    "    dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]][\"cum_passenger_count\"] = float(data[\"cum_passenger_count\"][i])\n",
    "    dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]][\"out_passenger\"] = float(data[\"out_passenger\"][i])\n",
    "    dict[data[\"line\"][i]][data[\"hour\"][i]][data[\"station\"][i]][\"current_passenger\"] = float(data[\"current_passenger\"][i])\n",
    "\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.read_excel(r\"data\\rayl-sistemlere-ait-hat-uzunluk-bilgileri.xlsx\")\n",
    "length_sum = length_df.groupby(length_df.columns[0])[length_df.columns[-1]].sum().reset_index()\n",
    "length_sum[length_sum.columns[-1]] = length_sum[length_sum.columns[-1]].astype(float) / 1000\n",
    "length_sum = length_sum.rename(columns={length_sum.columns[-1]: \"length(km)\"})\n",
    "lines = istanbul_metro.keys()\n",
    "#drop the lines that are not in the istanbul_metro\n",
    "length_sum = length_sum[length_sum[length_sum.columns[0]].isin(lines)]\n",
    "length_sum"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25fadb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>hour</th>\n",
       "      <th>station</th>\n",
       "      <th>in_passenger</th>\n",
       "      <th>cum_passenger_count</th>\n",
       "      <th>out_passenger</th>\n",
       "      <th>current_passenger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2</td>\n",
       "      <td>6</td>\n",
       "      <td>YENIKAPI</td>\n",
       "      <td>1198.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1198.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2</td>\n",
       "      <td>6</td>\n",
       "      <td>VEZNECILER</td>\n",
       "      <td>76.931960</td>\n",
       "      <td>1198.250000</td>\n",
       "      <td>33.553563</td>\n",
       "      <td>1241.628397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>6</td>\n",
       "      <td>HALIC</td>\n",
       "      <td>73.505744</td>\n",
       "      <td>1275.181960</td>\n",
       "      <td>34.075056</td>\n",
       "      <td>1314.612648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M2</td>\n",
       "      <td>6</td>\n",
       "      <td>SISHANE</td>\n",
       "      <td>153.935685</td>\n",
       "      <td>1348.687704</td>\n",
       "      <td>77.746613</td>\n",
       "      <td>1424.876776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M2</td>\n",
       "      <td>6</td>\n",
       "      <td>TAKSIM</td>\n",
       "      <td>238.817291</td>\n",
       "      <td>1502.623389</td>\n",
       "      <td>138.795570</td>\n",
       "      <td>1602.645110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>T5-R</td>\n",
       "      <td>23</td>\n",
       "      <td>BALAT</td>\n",
       "      <td>24.085976</td>\n",
       "      <td>331.864853</td>\n",
       "      <td>18.727333</td>\n",
       "      <td>337.223495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>T5-R</td>\n",
       "      <td>23</td>\n",
       "      <td>FENER</td>\n",
       "      <td>25.284440</td>\n",
       "      <td>355.950828</td>\n",
       "      <td>21.145353</td>\n",
       "      <td>360.089915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>T5-R</td>\n",
       "      <td>23</td>\n",
       "      <td>CIBALI</td>\n",
       "      <td>30.405205</td>\n",
       "      <td>381.235268</td>\n",
       "      <td>27.565720</td>\n",
       "      <td>384.074753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>T5-R</td>\n",
       "      <td>23</td>\n",
       "      <td>KUCUKPAZAR</td>\n",
       "      <td>39.270216</td>\n",
       "      <td>411.640473</td>\n",
       "      <td>39.270216</td>\n",
       "      <td>411.640473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>T5-R</td>\n",
       "      <td>23</td>\n",
       "      <td>EMINONU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.910689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.910689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5724 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      line  hour     station  in_passenger  cum_passenger_count  \\\n",
       "0       M2     6    YENIKAPI   1198.250000             0.000000   \n",
       "1       M2     6  VEZNECILER     76.931960          1198.250000   \n",
       "2       M2     6       HALIC     73.505744          1275.181960   \n",
       "3       M2     6     SISHANE    153.935685          1348.687704   \n",
       "4       M2     6      TAKSIM    238.817291          1502.623389   \n",
       "...    ...   ...         ...           ...                  ...   \n",
       "5719  T5-R    23       BALAT     24.085976           331.864853   \n",
       "5720  T5-R    23       FENER     25.284440           355.950828   \n",
       "5721  T5-R    23      CIBALI     30.405205           381.235268   \n",
       "5722  T5-R    23  KUCUKPAZAR     39.270216           411.640473   \n",
       "5723  T5-R    23     EMINONU      0.000000           450.910689   \n",
       "\n",
       "      out_passenger  current_passenger  \n",
       "0          0.000000        1198.250000  \n",
       "1         33.553563        1241.628397  \n",
       "2         34.075056        1314.612648  \n",
       "3         77.746613        1424.876776  \n",
       "4        138.795570        1602.645110  \n",
       "...             ...                ...  \n",
       "5719      18.727333         337.223495  \n",
       "5720      21.145353         360.089915  \n",
       "5721      27.565720         384.074753  \n",
       "5722      39.270216         411.640473  \n",
       "5723       0.000000         450.910689  \n",
       "\n",
       "[5724 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split['out_passenger'] = None\n",
    "\n",
    "for index, row in df_split.iterrows():\n",
    "    out = calculate_out_passenger_count(df_split, row['hour'], row['line'], row['station'])\n",
    "    df_split.at[index, 'out_passenger'] = out\n",
    "\n",
    "df_split['out_passenger'] = pd.to_numeric(df_split['out_passenger'], errors='coerce')\n",
    "df_split[\"current_passenger\"] = df_split[\"cum_passenger_count\"] - df_split[\"out_passenger\"] + df_split[\"in_passenger\"]\n",
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab8d9d64",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\rayl-sistemlere-ait-hat-uzunluk-bilgileri.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m length_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mrayl-sistemlere-ait-hat-uzunluk-bilgileri.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m length_sum \u001b[38;5;241m=\u001b[39m length_df\u001b[38;5;241m.\u001b[39mgroupby(length_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])[length_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      3\u001b[0m length_sum[length_sum\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m length_sum[length_sum\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\rayl-sistemlere-ait-hat-uzunluk-bilgileri.xlsx'"
     ]
    }
   ],
   "source": [
    "length_df = pd.read_excel(r\"data\\rayl-sistemlere-ait-hat-uzunluk-bilgileri.xlsx\")\n",
    "length_sum = length_df.groupby(length_df.columns[0])[length_df.columns[-1]].sum().reset_index()\n",
    "length_sum[length_sum.columns[-1]] = length_sum[length_sum.columns[-1]].astype(float) / 1000\n",
    "length_sum = length_sum.rename(columns={length_sum.columns[-1]: \"length(km)\"})\n",
    "lines = istanbul_metro.keys()\n",
    "#drop the lines that are not in the istanbul_metro\n",
    "length_sum = length_sum[length_sum[length_sum.columns[0]].isin(lines)]\n",
    "length_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "TL = 4.47884\n",
    "POPULATION_SIZE = 50\n",
    "OPERATIONAL_COST = 1000\n",
    "COT = 115\n",
    "GENERATIONS = 100\n",
    "FREQ_BOUNDS = (2, 10) \n",
    "STOP_TIME_BOUNDS = (20, 90)  # Seconds\n",
    "\n",
    "density_cost_w, standing_cost_w, time_w  = 3.0, 1.5, 115/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df = pd.read_excel(r\"data\\metro-hatlar-enerji-tuketimi.xlsx\")\n",
    "energy_df.drop(energy_df.columns[-1], axis=1, inplace=True)\n",
    "energy_df.columns = energy_df.iloc[0]\n",
    "energy_df = energy_df[1:].reset_index(drop=True)\n",
    "energy_df = energy_df[energy_df[\"Hat\"].isin(istanbul_metro.keys())]\n",
    "energy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_df = pd.read_csv(r\"data\\hat_ortalamalari.csv\")\n",
    "capacity_df = capacity_df[capacity_df[\"Hat\"].isin(istanbul_metro.keys())]\n",
    "capacity_df = capacity_df.rename(columns={\"Hat\": \"line\"})\n",
    "capacity_df[\"total_capacity\"] = capacity_df[\"koltuk\"] + capacity_df[\"ayakta\"]\n",
    "capacity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary for energy consumption and length\n",
    "line_info = {}\n",
    "for index, row in energy_df.iterrows():\n",
    "    line = row[\"Hat\"]\n",
    "    line_info[line] = {\n",
    "        \"energy\": float(row[\"100 KM'de Enerji Tüketimi (kWh)\"]),\n",
    "        \"length\": length_sum[length_sum[length_sum.columns[0]] == line][length_sum.columns[-1]].values[0]\n",
    "    }\n",
    "#calculate the energy consumption for each line\n",
    "for line in line_info.keys():\n",
    "    line_info[line][\"energy_cost\"] = line_info[line][\"energy\"] * line_info[line][\"length\"] / 100 *TL\n",
    "\n",
    "# add koltuk ayakta and total capacity to the line_info dictionary\n",
    "for index, row in capacity_df.iterrows():\n",
    "    line = row[\"line\"]\n",
    "    line_info[line][\"koltuk\"] = float(row[\"koltuk\"])\n",
    "    line_info[line][\"ayakta\"] = float(row[\"ayakta\"])\n",
    "    line_info[line][\"total_capacity\"] = line_info[line][\"koltuk\"] + line_info[line][\"ayakta\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "line_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(frequency, stop_time, line_data,line_info,line_name, time_w, density_cost_w, standing_cost_w):\n",
    "    # print(type(line_data), type(line_info), type(line_name), type(time_w), type(density_cost_w), type(standing_cost_w))\n",
    "    # print(line_data)\n",
    "    op_cost = 0\n",
    "    wait_cost = 0\n",
    "    unserved_cost = 0\n",
    "    density_cost = 0\n",
    "    standing_cost = 0\n",
    "    i = 0\n",
    "    unserved_cost_w = time_w * 3\n",
    "\n",
    "    for _, hour in line_data.items():\n",
    "        # print(\"hour\", type(hour))\n",
    "        # print(hour)\n",
    "        op_cost += frequency * line_info[line_name][\"energy_cost\"]\n",
    "        for _, station in hour.items():\n",
    "            # print(\"station\", type(station))\n",
    "            # print(station)\n",
    "            #print(type(station[\"in_passenger\"]), type(stop_time), type(frequency), type(station[\"cum_passenger_count\"]))\n",
    "            wait_cost += (station[\"in_passenger\"] * (60 / frequency)/2) * time_w +  ((station[\"cum_passenger_count\"] + station[\"in_passenger\"]) * stop_time / 60) * time_w\n",
    "            unserved_cost += max(0,(station[\"in_passenger\"] - max(0,(line_info[line_name][\"total_capacity\"] - station[\"cum_passenger_count\"])))) * (60 / frequency) * unserved_cost_w \n",
    "            density_cost += station[\"cum_passenger_count\"] / line_info[line_name][\"total_capacity\"] * density_cost_w \n",
    "            standing_cost += max(0,(station[\"cum_passenger_count\"] - line_info[line_name][\"koltuk\"])) * standing_cost_w\n",
    "        i += 1\n",
    "\n",
    "    return (op_cost + wait_cost + unserved_cost + density_cost + standing_cost)/i , op_cost/i, wait_cost/i, unserved_cost/i, density_cost/i, standing_cost/i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(pop_size, freq_bounds, stop_time_bounds):\n",
    "    population = []\n",
    "    for _ in range(int(pop_size)):\n",
    "        freq = random.uniform(*freq_bounds)\n",
    "        stop_time = random.uniform(*stop_time_bounds)\n",
    "        population.append([freq, stop_time])\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, line_data, line_info, line_name, w2, w3, w4):\n",
    "    fitness_values = []\n",
    "    op = []\n",
    "    wait = []\n",
    "    unserved = []\n",
    "    density = []\n",
    "    standing = []\n",
    "\n",
    "    for individual in population:\n",
    "        freq, stop_time = individual\n",
    "        cost, op_cost, wait_cost, unserved_cost, density_cost, standing_cost = cost_function(freq, stop_time, line_data, line_info, line_name, w2, w3, w4)\n",
    "        fitness_values.append(cost)\n",
    "        op.append(op_cost)\n",
    "        wait.append(wait_cost)\n",
    "        unserved.append(unserved_cost)\n",
    "        density.append(density_cost)\n",
    "        standing.append(standing_cost)\n",
    "    return fitness_values, op, wait, unserved, density, standing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population, fitness_values, tournament_size=3):\n",
    "    selected = []\n",
    "    pop_size = len(population)\n",
    "    for _ in range(pop_size):\n",
    "        contenders_idx = random.sample(range(pop_size), tournament_size)\n",
    "        contenders_fitness = [fitness_values[i] for i in contenders_idx]\n",
    "        winner_idx = contenders_idx[np.argmin(contenders_fitness)]\n",
    "        selected.append(population[winner_idx])\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    # Uniform crossover\n",
    "    child1, child2 = [], []\n",
    "    for gene1, gene2 in zip(parent1, parent2):\n",
    "        if random.random() < 0.5:\n",
    "            child1.append(gene1)\n",
    "            child2.append(gene2)\n",
    "        else:\n",
    "            child1.append(gene2)\n",
    "            child2.append(gene1)\n",
    "    return child1, child2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(individual, freq_bounds, stop_time_bounds, mutation_rate=0.1, mutation_scale=0.1):\n",
    "    # Mutate frequency\n",
    "    if random.random() < mutation_rate:\n",
    "        mutation = random.uniform(-mutation_scale, mutation_scale) * (freq_bounds[1] - freq_bounds[0])\n",
    "        individual[0] = np.clip(individual[0] + mutation, *freq_bounds)\n",
    "    # Mutate stop_time\n",
    "    if random.random() < mutation_rate:\n",
    "        mutation = random.uniform(-mutation_scale, mutation_scale) * (stop_time_bounds[1] - stop_time_bounds[0])\n",
    "        individual[1] = np.clip(individual[1] + mutation, *stop_time_bounds)\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(line_data, line_info, line_name, \n",
    "                      pop_size=POPULATION_SIZE, generations=GENERATIONS, \n",
    "                      freq_bounds=FREQ_BOUNDS, stop_time_bounds=STOP_TIME_BOUNDS,\n",
    "                      w2=density_cost_w, w3=standing_cost_w, w4=time_w):\n",
    "\n",
    "    population = initialize_population(pop_size, freq_bounds, stop_time_bounds)\n",
    "    \n",
    "    best_solution = None\n",
    "    best_fitness = float('inf')\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        fitness_values, op, wait, unserved, density, standing = evaluate_population(population, line_data, line_info, line_name, w2, w3, w4)\n",
    "\n",
    "        # Track best solution\n",
    "        min_idx = np.argmin(fitness_values)\n",
    "        if fitness_values[min_idx] < best_fitness:\n",
    "            best_fitness = fitness_values[min_idx]\n",
    "            best_solution = population[min_idx]\n",
    "            best_op = op[min_idx]\n",
    "            best_wait = wait[min_idx]\n",
    "            best_unserved = unserved[min_idx]\n",
    "            best_density = density[min_idx]\n",
    "            best_standing = standing[min_idx]\n",
    "            \n",
    "        \n",
    "        print(f\"Generation {gen+1}, Best Cost: {best_fitness:.4f}, Best Operational Cost: {best_op:.4f}, \"\n",
    "              f\"Best Wait Cost: {best_wait:.4f}, Best Unserved Cost: {best_unserved:.4f}, Best Density Cost: {best_density:.4f}, \"\n",
    "              f\"Best Standing Cost: {best_standing:.4f}, Frequency: {best_solution[0]:.2f}, Stop Time: {best_solution[1]:.2f}\")\n",
    "\n",
    "        # Selection\n",
    "        selected = tournament_selection(population, fitness_values)\n",
    "\n",
    "        # Create next generation\n",
    "        next_population = []\n",
    "        for i in range(0, pop_size, 2):\n",
    "            parent1 = selected[i]\n",
    "            parent2 = selected[(i+1) % pop_size]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            child1 = mutate(child1, freq_bounds, stop_time_bounds)\n",
    "            child2 = mutate(child2, freq_bounds, stop_time_bounds)\n",
    "            next_population.extend([child1, child2])\n",
    "        \n",
    "        population = next_population[:pop_size]  # Ensure population size\n",
    "\n",
    "    return best_solution, best_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (for line \"M2\", replace with your actual line data):\n",
    "best_params, best_cost = genetic_algorithm(\n",
    "    dict[\"M2\"], line_info, \"M2\", w2=density_cost_w, w3=standing_cost_w, w4=time_w\n",
    ")\n",
    "print(f\"Best frequency: {best_params[0]}, Best stop time: {best_params[1]}, Cost: {best_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
